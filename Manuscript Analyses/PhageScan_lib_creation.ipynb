{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a7fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9bc8afe-fb4e-414b-a49f-70f294d8671d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function definitions\n",
    "\n",
    "def isNaN(num):\n",
    "    return num != num\n",
    "\n",
    "def proteinSetOfPhageSet(phageset):\n",
    "    my_protein_clusters = dict()\n",
    "    mark_for_write = False\n",
    "    count_X = 0\n",
    "    count_proteins = 0\n",
    "    with open(GPD_proteins) as seq_file:\n",
    "        for line in seq_file:\n",
    "            if line.startswith(\">\"):\n",
    "                identifier = line.strip()[1:]\n",
    "                phageID = \"_\".join(identifier.split(\"_\")[0:2])\n",
    "                if phageID in phageset:\n",
    "                    mark_for_write = True\n",
    "                else:\n",
    "                    mark_for_write = False\n",
    "            else:\n",
    "                if mark_for_write:\n",
    "                    if \"X\" not in line:\n",
    "                        count_proteins += 1\n",
    "                        if identifier in protein_clusters:\n",
    "                            cluster_name = protein_clusters[identifier]\n",
    "                        else:\n",
    "                            cluster_name = identifier\n",
    "                        if cluster_name not in my_protein_clusters:\n",
    "                            my_protein_clusters[cluster_name] = []\n",
    "                        my_protein_clusters[cluster_name].append({\"proteinID\":identifier,\"seq\":line, \"size\":len(line)})\n",
    "\n",
    "                    else:\n",
    "                        count_X = count_X +1\n",
    "\n",
    "    print(count_proteins, \"proteins found in\", len(my_protein_clusters), \"clusters, and additional\",count_X,\"proteins countain X\")\n",
    "    return(my_protein_clusters)\n",
    "\n",
    "def tileProtSeqWOverlap(aa_seq, tilesize, overlap = -1):\n",
    "    # start tiles from both side, let \"middle tile\" over lap with already existing tiles\n",
    "    # start second overlapping set from the middle in both directions to the side\n",
    "    # ____   ___   ____ #\n",
    "    #    ____   ____  #\n",
    "    if overlap == -1:\n",
    "        overlap = int(tilesize/2)\n",
    "    tiles = []\n",
    "    center = int(len(aa_seq)/2)\n",
    "    seq = aa_seq[:center]\n",
    "    pos = 0\n",
    "    \n",
    "    if len(aa_seq) >= tilesize:\n",
    "        while len(seq) >= tilesize:\n",
    "            tiles.append((seq[:tilesize],pos))\n",
    "            seq = seq[tilesize-overlap:]\n",
    "            pos = pos + tilesize - overlap\n",
    "        tiles.append((aa_seq[pos:pos+tilesize],pos))\n",
    "        seq = aa_seq[center:]\n",
    "        pos = len(aa_seq) - tilesize\n",
    "        while len(seq) >= tilesize:\n",
    "            tiles.append((seq[-tilesize:],pos))\n",
    "            seq = seq[:-(tilesize-overlap)]\n",
    "            pos = pos-tilesize+overlap   \n",
    "        last_tile = (aa_seq[pos:pos+tilesize],pos)\n",
    "        if aa_seq[pos:pos+tilesize] != \"\" and last_tile not in tiles:\n",
    "            tiles.append(last_tile)\n",
    "    else:\n",
    "        tiles.append((aa_seq, -1))\n",
    "        \n",
    "    return(tiles)\n",
    "\n",
    "def find_all(a_str, sub):\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = a_str.find(sub, start)\n",
    "        if start == -1: return\n",
    "        yield start\n",
    "        start += len(sub) # use start += 1 to find overlapping matches\n",
    "        \n",
    "def find_all_proteins_in_str(long_string):\n",
    "    idxs = list(find_all(long_string, 'vig')) \n",
    "    prots = set()\n",
    "    for i in idxs:\n",
    "        t = long_string[i-1:]\n",
    "        ps= \"_\".join(t.split(\"_\")[0:3]).split(\"'\")[0].split(\"pos\")[0]\n",
    "        prots.add(ps)\n",
    "    return prots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692ee94-09a8-42ff-bb2b-82ca3e9a9982",
   "metadata": {},
   "source": [
    "# GPD Analysis - Count Phages and Proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1996ae2-4c61-4b23-aa54-25312093a039",
   "metadata": {},
   "source": [
    "Download GPD files from\n",
    "\n",
    "Luis F. Camarillo-Guerrero, Alexandre Almeida, Guillermo Rangel-Pineros, Robert D. Finn, Trevor D. Lawley,\n",
    "Massive expansion of human gut bacteriophage diversity,\n",
    "Cell, 2021, https://doi.org/10.1016/j.cell.2021.01.029.\n",
    "\n",
    "affiliated data:\n",
    "http://ftp.ebi.ac.uk/pub/databases/metagenomics/genome_sets/gut_phage_database/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06febb84-b564-4457-bf9a-1c8bba128b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_clusters_file =\"../../PCs_GPD.txt\"\n",
    "protein_clusters = dict()\n",
    "with open(protein_clusters_file) as myfile:\n",
    "    for line in myfile.readlines():\n",
    "        line = line.strip()\n",
    "        rep = line.split(\"\\t\")[0]\n",
    "        for phID in line.split(\"\\t\"):\n",
    "            protein_clusters[phID] = rep\n",
    "            \n",
    "GPD_proteins = \"../../GPD_proteome.faa\"\n",
    "phage_meta_df = pd.read_table(\"../../GPD_phage_metadata.csv\", sep = \",\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2074f757-d124-4552-adf1-d704440ee32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Phages in GPD 142810\n"
     ]
    }
   ],
   "source": [
    "my_phages = set()\n",
    "for index, row in phage_meta_df.iterrows():\n",
    "    my_phages.add(index)\n",
    "\n",
    "print(\"All Phages in GPD\", len(my_phages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "208773ec-00bb-45d9-b6af-460b07b1edda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7581279 proteins found in 309842 clusters, and additional 528 proteins countain X\n"
     ]
    }
   ],
   "source": [
    "_ = proteinSetOfPhageSet(my_phages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1748bd10-ed60-451a-ad1b-21005b554ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HQ (checkV_MIUViG = 'High-quality') Phages with at least 1 detected Sample 38848\n"
     ]
    }
   ],
   "source": [
    "my_phages = set()\n",
    "for index, row in phage_meta_df.iterrows():\n",
    "    if row[\"checkV_MIUViG\"] == \"High-quality\":\n",
    "        if not isNaN(row[\"Continents_detected\"]):\n",
    "            my_phages.add(index)\n",
    "\n",
    "print(\"HQ (checkV_MIUViG = 'High-quality') Phages with at least 1 detected Sample\", len(my_phages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ddd7ca7-ae8f-4ef1-816d-6ab45a3bacae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HQ (checkV_MIUViG = 'High-quality') Phages: 41427\n"
     ]
    }
   ],
   "source": [
    "my_phages = set()\n",
    "for index, row in phage_meta_df.iterrows():\n",
    "    if row[\"checkV_MIUViG\"] == \"High-quality\":\n",
    "        my_phages.add(index)\n",
    "\n",
    "print(\"HQ (checkV_MIUViG = 'High-quality') Phages:\", len(my_phages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b0e3b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HQ (checkV_MIUViG = 'High-quality') Phages with at least 1 North American Sample 7614\n"
     ]
    }
   ],
   "source": [
    "my_phages = set()\n",
    "for index, row in phage_meta_df.iterrows():\n",
    "    if row[\"checkV_MIUViG\"] == \"High-quality\":\n",
    "        if not isNaN(row[\"Continents_detected\"]):\n",
    "            countrylist = row[\"Continents_detected\"].split(\",\") \n",
    "            if 'North America' in countrylist :\n",
    "                if countrylist.count(\"North America\") > 0 :\n",
    "                    my_phages.add(index)\n",
    "\n",
    "print(\"HQ (checkV_MIUViG = 'High-quality') Phages with at least 1 North American Sample\", len(my_phages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86a9300c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588783 proteins found in 84306 clusters, and additional 47 proteins countain X\n"
     ]
    }
   ],
   "source": [
    "phageome_clusters = proteinSetOfPhageSet(my_phages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f82779-c28d-4e12-adcf-4fe979990592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HQ (checkV_MIUViG = 'High-quality') prevalent (>50 samples) North American Phages 112\n"
     ]
    }
   ],
   "source": [
    "my_phages = set()\n",
    "for index, row in phage_meta_df.iterrows():\n",
    "    if row[\"checkV_MIUViG\"] == \"High-quality\":\n",
    "        if not isNaN(row[\"Continents_detected\"]):\n",
    "            countrylist = row[\"Continents_detected\"].split(\",\") \n",
    "            if 'North America' in countrylist :\n",
    "                if countrylist.count(\"North America\") > 50 :\n",
    "                    my_phages.add(index)\n",
    "\n",
    "print(\"HQ (checkV_MIUViG = 'High-quality') prevalent (>50 samples) North American Phages\", len(my_phages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a32000a8-95b3-4df6-b8c7-2ed969ada9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8023 proteins found in 3354 clusters, and additional 6 proteins countain X\n"
     ]
    }
   ],
   "source": [
    "phageome_pilot_clusters = proteinSetOfPhageSet(my_phages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbfb54d5-9f2b-48e3-93d0-b36eedd34fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_seq_file = \"../data/PhageScan_pilot_proteinClusterReps.faa\"\n",
    "my_protein_clusters = phageome_pilot_clusters\n",
    "\n",
    "# For \"FULL\" design (\"theoretical design\" in Manuscript) uncomment the following two lines\n",
    "#write_file_name = \"PhageScan_proteinClusterReps.faa\"\n",
    "#my_protein_clusters = phageome_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cb83df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(protein_seq_file,'w') as write_file:\n",
    "    for cluster in my_protein_clusters.values():\n",
    "        identifier = \"\"\n",
    "        longest = 0\n",
    "        for protein in cluster:\n",
    "            identifier += protein[\"proteinID\"] +\"_\"\n",
    "            if protein[\"size\"]>longest:\n",
    "                longest = protein[\"size\"]\n",
    "                representative_seq = protein[\"seq\"]\n",
    "                repID = protein[\"proteinID\"]\n",
    "                \n",
    "        write_file.write(\">REP_\"+repID+\"_ALL_\"+identifier[:-1] + \"\\n\")\n",
    "        write_file.write(representative_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6e5f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of all proteins together: 750776 aa\n"
     ]
    }
   ],
   "source": [
    "l = 0\n",
    "with open(protein_seq_file) as seq_file:\n",
    "    for line in seq_file:\n",
    "        if not line.startswith(\">\"):\n",
    "            seq = line[:-1]\n",
    "            l+=len(seq)\n",
    "print(\"length of all proteins together:\",l,\"aa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6d54b",
   "metadata": {},
   "source": [
    "# Simple tiling approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aae5c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23745 unique tiles\n"
     ]
    }
   ],
   "source": [
    "tilesize = 56\n",
    "overlap = int(tilesize/2)\n",
    "\n",
    "pepsyn_all_tiles = dict()\n",
    "\n",
    "with open(protein_seq_file) as rep_file:\n",
    "    for line in rep_file:\n",
    "        if not line.startswith(\">\"):\n",
    "            seq = line.strip()\n",
    "            tile_vec = tileProtSeqWOverlap(seq, tilesize, overlap)\n",
    "            for tile, pos in tile_vec:\n",
    "                if tile not in pepsyn_all_tiles:\n",
    "                    pepsyn_all_tiles[tile] = []\n",
    "                pepsyn_all_tiles[tile].append(str(protein)+\"pos_\"+str(pos))\n",
    "        else:\n",
    "            protein = line.strip()[1:]\n",
    "                \n",
    "print(len(pepsyn_all_tiles),\"unique tiles\")\n",
    "no_pepsyn_tiles = len(pepsyn_all_tiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec6e59",
   "metadata": {},
   "source": [
    "# Dolphyn tyling approach\n",
    "check out notebook Dolphyn_library_design.ipynb for more guidance on using Dolphyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5b03f9d-ec03-430a-8732-9a7a3e14b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../dolphyn'))\n",
    "import dolphyn as D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4345fb1-7ab6-486c-a05a-739b2c4f18ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes time (~25min on my laptop), uncomment to run!\n",
    "ge = D.findEpitopes(testrun = 0, protein_seq_file = protein_seq_file, epitile_size=15)\n",
    "dolphyn_tiles, _ = D.peptideStitching(no_epis_per_tile = 3, linker_seq = \"GGGGS\" , global_epitopes = ge, return_unused_epis = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e25e4",
   "metadata": {},
   "source": [
    "\n",
    "# Build final library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b309816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_file = \"phageScan_proteins.faa\"\n",
    "dna_file_noadap = \"phageome_peptides_oligos_noadap.fasta\"\n",
    "dna_file = \"phageScan_peptides_oligos.fasta\"\n",
    "\n",
    "five_prime_adapter = \"AGGAATTCCGCTGCGT\"\n",
    "three_prime_adapter = \"ATGGTCACAGCTGTGC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2a636c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = dict()\n",
    "AMINOACIDS = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "def junkseq(length):\n",
    "    return((\"***\" + \"\".join(random.choice(AMINOACIDS) for i in range(length)))[:length])\n",
    "\n",
    "with open(prot_file, \"w\") as pf:\n",
    "    for seq, tile in dolphyn_tiles.items():\n",
    "        n = str(tile[\"protein set\"])+\"_\"+str(tile[\"tile number\"])+\"of\"+str(tile[\"tiles in protein(set)\"])\n",
    "        h = abs(hash(n))\n",
    "        anno[\"dolphyn_\"+str(h)] = \"dolphyn_\"+n\n",
    "        pf.write(\">\"+\"dolphyn_\"+str(h)+\"\\n\")\n",
    "        pf.write(seq+\"*\\n\")\n",
    "        \n",
    "    for seq, prots in pepsyn_all_tiles.items():\n",
    "        n = str(prots)\n",
    "        h = abs(hash(n))\n",
    "        anno[\"pepsyn_\"+str(h)] = \"pepsyn_\"+n\n",
    "        pf.write(\">\"+\"pepsyn_\"+str(h)+\"\\n\")\n",
    "        pf.write(seq + junkseq(56-len(seq))+\"\\n\")\n",
    "        \n",
    "    for seq, tile in ge.items():\n",
    "        n = str(tile[\"proteins\"])+\"_\"+str(tile[\"start_pos\"])+\"_\"+str(tile[\"probability\"])\n",
    "        h = abs(hash(n))\n",
    "        anno[\"dolphynepitopes_\"+str(h)] = \"dolphynepitopes_\"+n\n",
    "        pf.write(\">\"+\"dolphynepitopes_\"+str(h)+\"\\n\")\n",
    "        pf.write(\"GGGGS\" + seq+ junkseq(36) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb89e7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pepsyn revtrans phageScan_proteins.faa phageome_peptides_oligos_noadap.fasta'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revtrans_command = \"pepsyn revtrans \"+ prot_file + \" \" + dna_file_noadap\n",
    "stream = os.popen(revtrans_command)\n",
    "output = stream.read().strip()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6604dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dna_file_noadap, \"r\") as na:\n",
    "    with open(dna_file, \"w\") as wa:\n",
    "        for line in na:\n",
    "            l = line.strip()\n",
    "            if not line.startswith(\">\"):\n",
    "                l = five_prime_adapter + l + three_prime_adapter\n",
    "            wa.write(l+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2631cfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 23758.0 dolphyn: 3 epitopes: 10 pepsyn: 23745\n"
     ]
    }
   ],
   "source": [
    "dolp = 0\n",
    "epis = 0\n",
    "peps = 0\n",
    "total = 0\n",
    "with open(dna_file, \"r\") as wa:\n",
    "    for line in wa:\n",
    "        total +=1\n",
    "        if line.startswith(\">dolphyn_\"):\n",
    "            dolp += 1\n",
    "        elif line.startswith(\">dolphynepitopes_\"):\n",
    "            epis += 1\n",
    "        elif line.startswith(\">pepsyn_\"):\n",
    "            peps += 1\n",
    "            \n",
    "print(\"total:\", total/2 , \"dolphyn:\", dolp, \"epitopes:\", epis, \"pepsyn:\", peps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277bf24f",
   "metadata": {},
   "source": [
    "# Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43fd010a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annoall = pd.DataFrame(anno.items(), columns = [\"tile_id\",\"allinfo\"])\n",
    "annoall.index = annoall[\"tile_id\"]\n",
    "annoall[\"library\"] = [el[0] for el in annoall['tile_id'].str.split(\"_\")]\n",
    "annoall[\"AA\"] = \"\"\n",
    "annoall[\"oligo\"] = \"\"\n",
    "identifier = \"\"\n",
    "with open(dna_file_noadap, \"r\") as wa:\n",
    "    for line in wa:\n",
    "        if line.startswith(\">\"):\n",
    "            identifier = line.strip()[1:]\n",
    "        else:\n",
    "            annoall.loc[identifier, \"oligo\"] = line.strip()\n",
    "identifier = \"\"\n",
    "with open(prot_file, \"r\") as wa:\n",
    "    for line in wa:\n",
    "        if line.startswith(\">\"):\n",
    "            identifier = line.strip()[1:]\n",
    "        else:\n",
    "            annoall.loc[identifier, \"AA\"] = line.strip()\n",
    "\n",
    "annoall.drop(\"tile_id\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3f8caa7-95c6-49c3-8634-a1f0456dc216",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict = dict()\n",
    "for allinfo in annoall[annoall.library=='pepsyn'].allinfo:\n",
    "    splits = allinfo.split(\"pos_\")\n",
    "    if len(splits) == 3:\n",
    "        protein = splits[0].split(\"REP_\")[1].split(\"_ALL_\")[0]\n",
    "        pos = pd.to_numeric(splits[1].split(\"'\")[0])\n",
    "        if protein not in position_dict:\n",
    "            position_dict[protein] = []\n",
    "        position_dict[protein].append(pos)\n",
    "        protein = splits[1].split(\"', 'REP_\")[1].split(\"_ALL_\")[0]\n",
    "        pos = pd.to_numeric(splits[2].split(\"'\")[0])\n",
    "        if protein not in position_dict:\n",
    "            position_dict[protein] = []\n",
    "        position_dict[protein].append(pos)\n",
    "    else:\n",
    "        protein = splits[0].split(\"REP_\")[1].split(\"_ALL_\")[0]\n",
    "        pos = pd.to_numeric(splits[1].split(\"'\")[0])\n",
    "        if protein not in position_dict:\n",
    "            position_dict[protein] = []\n",
    "        position_dict[protein].append(pos)\n",
    "\n",
    "for k in position_dict:\n",
    "    position_dict[k].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e9443a5-b1fb-4834-a970-2f9fd25e6065",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict_epis = dict()\n",
    "for allinfo in annoall[annoall.library=='dolphynepitopes'].allinfo:\n",
    "    splits = allinfo.split(\"REP_\")\n",
    "    no_prot = len(splits)-1\n",
    "    if no_prot > 0:\n",
    "        #print(allinfo)\n",
    "        for ix in range(no_prot):\n",
    "            protein = splits[ix+1].split(\"_ALL\")[0]\n",
    "            pos = pd.to_numeric(splits[-1].split(\"[\")[1].split(\"]\")[0].split(\", \")[ix])\n",
    "            if protein not in position_dict_epis:\n",
    "                position_dict_epis[protein] = []\n",
    "            position_dict_epis[protein].append(pos)\n",
    "            \n",
    "for k in position_dict_epis:\n",
    "    position_dict_epis[k].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9e7532e-e9bd-4779-8959-356f6204e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteinseqs = dict()\n",
    "with open(protein_seq_file) as seq_file:\n",
    "    for line in seq_file:\n",
    "        if line.startswith(\">\"):\n",
    "            identifier = line.strip()[5:].split(\"_ALL_\")[0]\n",
    "            #print(identifier)\n",
    "        else:\n",
    "            if identifier in proteinseqs:\n",
    "                print(\"WARNING! Identifier already exists\", identifier)\n",
    "            else:\n",
    "                proteinseqs[identifier] = line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7735f97-768e-4072-b4f2-f55658bbde2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inhouse_annotation_standard = ['u_pep_id', 'pep_id', 'pro_id', 'pep_rank', 'pos_start', 'pos_end',\n",
    "       'UniProt_acc', 'pep_dna', 'pep_aa', 'pro_len', 'pro_motifs', 'GO',\n",
    "       'RefSeq', 'taxon_id', 'taxon_species', 'taxon_genus', 'gene_symbol',\n",
    "       'gene_synonym', 'product', 'description', 'Pfam', 'EMBL', 'InterPro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "126015a1-bd14-44ce-a3a8-6304101323b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = pd.DataFrame(columns = inhouse_annotation_standard + [\"pro_id_all\",\"Host_range_taxon\",\"sublibrary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f0241d4-e605-4717-b6c3-c3a2cd21fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno.u_pep_id = \"DolphynLa_001_\" + annoall.oligo.str.slice(0,50)\n",
    "anno.pep_id = annoall.index\n",
    "anno.pep_dna = annoall.oligo\n",
    "anno.pep_aa = annoall.AA\n",
    "anno.sublibrary = annoall.library\n",
    "#dolphyn tiles contain three epitopes and therefore no start position\n",
    "anno.pro_id[annoall.index.str.startswith(\"dolphyn_\")] = annoall.allinfo[annoall.index.str.startswith(\"dolphyn_\")].str.split(\"_ALL_\").str[0].str.slice(14)\n",
    "anno.pep_rank[annoall.index.str.startswith(\"dolphyn_\")] = annoall.allinfo[annoall.index.str.startswith(\"dolphyn_\")].str.split(\"of\").str[0].str.split(\"_\").str[-1]\n",
    "#dolphyn epitopes may appear in more than one protein\n",
    "anno.pro_id[annoall.index.str.startswith(\"dolphynepi\")] = annoall.allinfo[annoall.index.str.startswith(\"dolphynepi\")].str.split(\"_ALL\").str[0].str.slice(22)\n",
    "anno.pos_start[annoall.index.str.startswith(\"dolphynepi\")] = pd.to_numeric(annoall.allinfo[annoall.index.str.startswith(\"dolphynepi\")].str.split(\"[\").str[2].str.split(\",\").str[0].str.split(\"]\").str[0])\n",
    "anno.pos_end[annoall.index.str.startswith(\"dolphynepi\")] = pd.to_numeric(annoall.allinfo[annoall.index.str.startswith(\"dolphynepi\")].str.split(\"[\").str[2].str.split(\",\").str[0].str.split(\"]\").str[0])+15\n",
    "anno.pep_rank[(anno.sublibrary == \"dolphynepitopes\")] = anno[(anno.sublibrary == \"dolphynepitopes\")].apply(lambda x: position_dict_epis[x.pro_id].index(x.pos_start), axis = 1) + 1\n",
    "#pepsyn tiles MAY occur in more than one protein\n",
    "anno.pro_id[annoall.index.str.startswith(\"pep\")] = annoall.allinfo[annoall.index.str.startswith(\"pep\")].str.split(\"_ALL\").str[0].str.slice(13)\n",
    "anno.pos_start[annoall.index.str.startswith(\"pep\")] = pd.to_numeric(annoall.allinfo[annoall.index.str.startswith(\"pep\")].str.split(\"pos_\").str[1].str.split(\"'\").str[0])\n",
    "anno.pos_end[annoall.index.str.startswith(\"pep\")] = pd.to_numeric(annoall.allinfo[annoall.index.str.startswith(\"pep\")].str.split(\"pos_\").str[1].str.split(\"'\").str[0]) + 56\n",
    "anno.pep_rank[(anno.sublibrary == \"pepsyn\")&(~anno.pro_id.isna())&(~anno.pos_start.isna())] = anno[(anno.sublibrary == \"pepsyn\")&(~anno.pro_id.isna())&(~anno.pos_start.isna())].apply(lambda x: position_dict[x.pro_id].index(x.pos_start), axis = 1) + 1\n",
    "#all proteins start with ivig or uvig\n",
    "anno.pro_id_all[annoall.index.str.startswith(\"dolphyn\")] = annoall.allinfo[annoall.index.str.startswith(\"dolphyn\")].apply(find_all_proteins_in_str)\n",
    "anno.pro_id_all[annoall.index.str.startswith(\"pep\")] = annoall.allinfo[annoall.index.str.startswith(\"pep\")].apply(find_all_proteins_in_str)\n",
    "anno.pro_len[~anno.pro_id.isna()] = anno.pro_id[~anno.pro_id.isna()].apply(lambda x: len(proteinseqs[x]))\n",
    "anno.taxon_id[~anno.pro_id.isna()] = anno.pro_id[~anno.pro_id.isna()].str.split(\"_\").str[:2].apply(lambda x: \"_\".join(x))\n",
    "anno.taxon_species[~anno.taxon_id.isna()] = phage_meta_df.loc[anno.taxon_id[~anno.taxon_id.isna()],\"Predicted_phage_taxon\"]\n",
    "anno.Host_range_taxon[~anno.taxon_id.isna()] = phage_meta_df.loc[anno.taxon_id[~anno.taxon_id.isna()],\"Host_range_taxon\"]\n",
    "# use only first protein for pep_rank\n",
    "# pepsyn repeated tiles: pepsyn_488986999078171116,pepsyn_7965792066393306560,pepsyn_8667934916366736320,pepsyn_9099708212137372566\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33d2f0f4-d12e-483a-9b81-adb1dba542b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anno.to_csv(\"PhageScan_PeptideAnno.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d116e-992a-45db-9847-5b214a0aef39",
   "metadata": {},
   "source": [
    "#### be aware that different versions may alter the random state for balancing training data and the random forest itself and therefore lead to differently chosen peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea11242-01db-4ad3-bdc3-9b3e73fee26a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
